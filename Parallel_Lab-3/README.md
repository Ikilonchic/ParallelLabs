# Отчет по лабораторной работе №3

по дисциплине "Параллельные и распредлённые вычисления"
студента группы ПА-18-2
Куца Никиты Юрьевича

## Постановка задачи

* Написать программу на языке С, которая будет использоваться двумя процессами;
* Организовать передачу одномерного массива с нулевого процесса к первому;
* Вычислить сумму всех элементов массива и разоослать всем процессам;
* Организовать вывод результата на нулевом процессе;
* Использовать `MPI_Send` и `MPI_Recv`.

## Выполнение

В программе использовались функции MPI:

* `int MPI_Init(int *argc, char ***argv)` - инициализирует MPI окружение:
  * `argc` - колличество аргументов командной стороки;
  * `argv` - массив аргументов командной строки.

* `int MPI_Comm_size(MPI_Comm comm, int *size)` - определяет размер группы, связанной с коммуникатором:
  * `comm` - коммуникатор, используется `MPI_COMM_WORLD` - начальный внутренний комуникатор для всех процессов;
  * `size` - количество процессов в группе.

* `int MPI_Comm_rank(MPI_Comm comm, int *rank)` - определяет номер процесса в коммуникаторе:
  * `comm` - коммуникатор;
  * `rank` - указатель на выделенную память для номера.

* `int MPI_Get_processor_name(char *name, int *resultlen)` - Отримує назву\ім'я процессору:
  * `name` - выделенная память для имени процесса;
  * `resultlen` - длина имени.

* `int MPI_Send(const void *buf, int count,
                MPI_Datatype datatype, int dest,
                int tag, MPI_Comm comm)` - блокирующая отправка сообщения:
  * `buf` - буфер, что нужно отправить;
  * `count` - колличество элементов в буфере;
  * `datatype` - тип данных в буфере;
  * `dest` - номер процесса-получателя;
  * `tag` - тег сообщения;
  * `comm` - коммуникатор.

* `int MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag,
  MPI_Comm comm, MPI_Status *status)` - блокирующее получение сообщения
  * `buf` - буфер, что нужно отправить;
  * `count` - колличество элементов в буфере;
  * `datatype` - тип данных в буфере;
  * `source` - номер процесса-отправителя;
  * `tag` - тег сообщения;
  * `comm` - коммуникатор;
  * `status` - статус.

* `int MPI_Finalize(void)` - завершает MPI окружение.

## Анализ результатов

Компилируем программу и запускаем ее с помощью команды `mpiexec`. Для указания количества запущенных процессов вводим флаг `-n` командной строки с численным параметром от 0 до допустимого количества.

Программа работает корректно только если запущенно минимум 2 процесса:

![mpi-example][mpi-example]

Пример работы программы с 2 процессами:

![mpi-example-n=2][mpi-example-n=2]

Пример работы программы с 4 процессами:

![mpi-example-n=4][mpi-example-n=4]

[mpi-example]: img/mpi-example.png
[mpi-example-n=2]: img/mpi-example-n=2.png
[mpi-example-n=4]: img/mpi-example-n=4.png
